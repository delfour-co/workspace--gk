version: '3.9'

# =============================================================================
# GK Mail - Production Docker Compose
# =============================================================================
# Features:
# - Secrets management
# - Health checks
# - Resource limits
# - Restart policies
# - Logging configuration
# - Network isolation
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # Mail Server (SMTP + IMAP)
  # ---------------------------------------------------------------------------
  mail-rs:
    build:
      context: .
      dockerfile: Dockerfile.optimized
      target: mail-rs
      cache_from:
        - gk-mail-rs:latest
    image: gk-mail-rs:${VERSION:-latest}
    container_name: gk-mail-rs
    restart: unless-stopped

    networks:
      - gk-backend
      - gk-mail

    ports:
      - "25:2525"      # SMTP
      - "143:1993"     # IMAP
      - "8080:8080"    # Health/Metrics

    volumes:
      - mail-data:/data
      - mail-maildir:/tmp/maildir
      - mail-queue:/data/queue
      - mail-db:/data/db

    environment:
      RUST_LOG: ${RUST_LOG:-info}
      DOMAIN: ${MAIL_DOMAIN:-localhost}
      SMTP_ADDR: 0.0.0.0:2525
      IMAP_ADDR: 0.0.0.0:1993
      MAILDIR_PATH: /tmp/maildir
      DATABASE_URL: sqlite:///data/db/users.db
      # TLS Configuration
      TLS_CERT_PATH: /run/secrets/mail_tls_cert
      TLS_KEY_PATH: /run/secrets/mail_tls_key

    secrets:
      - mail_tls_cert
      - mail_tls_key

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,component"
        tag: "{{.Name}}/{{.ID}}"

  # ---------------------------------------------------------------------------
  # MCP Mail Server
  # ---------------------------------------------------------------------------
  mcp-mail-server:
    build:
      context: .
      dockerfile: Dockerfile.optimized
      target: mcp-mail-server
      cache_from:
        - gk-mcp-mail:latest
    image: gk-mcp-mail:${VERSION:-latest}
    container_name: gk-mcp-mail
    restart: unless-stopped

    networks:
      - gk-backend

    ports:
      - "8090:8090"

    volumes:
      - mail-maildir:/data/maildir:ro  # Read-only access

    environment:
      RUST_LOG: ${RUST_LOG:-info}
      MCP_PORT: 8090
      MAILDIR_PATH: /data/maildir
      SMTP_HOST: mail-rs
      SMTP_PORT: 2525

    depends_on:
      mail-rs:
        condition: service_healthy

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # AI Runtime
  # ---------------------------------------------------------------------------
  ai-runtime:
    build:
      context: .
      dockerfile: Dockerfile.optimized
      target: ai-runtime
      cache_from:
        - gk-ai-runtime:latest
    image: gk-ai-runtime:${VERSION:-latest}
    container_name: gk-ai-runtime
    restart: unless-stopped

    networks:
      - gk-backend
      - gk-frontend

    ports:
      - "8888:8888"

    environment:
      RUST_LOG: ${RUST_LOG:-info}
      AI_PORT: 8888
      MCP_URL: http://mcp-mail-server:8090
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.1:8b}
      # API Keys (via secrets)
      OPENAI_API_KEY_FILE: /run/secrets/openai_api_key

    secrets:
      - openai_api_key

    depends_on:
      mcp-mail-server:
        condition: service_healthy
      ollama:
        condition: service_healthy

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8888/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s

    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # Ollama (LLM)
  # ---------------------------------------------------------------------------
  ollama:
    image: ollama/ollama:${OLLAMA_VERSION:-latest}
    container_name: gk-ollama
    restart: unless-stopped

    networks:
      - gk-backend

    ports:
      - "11434:11434"

    volumes:
      - ollama-data:/root/.ollama

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s

    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

    # Uncomment for GPU support
    # runtime: nvidia
    # environment:
    #   NVIDIA_VISIBLE_DEVICES: all

  # ---------------------------------------------------------------------------
  # Reverse Proxy (optional - for production)
  # ---------------------------------------------------------------------------
  proxy:
    build:
      context: .
      dockerfile: Dockerfile.optimized
      target: proxy-rs
      cache_from:
        - gk-proxy:latest
    image: gk-proxy:${VERSION:-latest}
    container_name: gk-proxy
    restart: unless-stopped

    networks:
      - gk-frontend

    ports:
      - "80:80"
      - "443:443"

    volumes:
      - proxy-certs:/data/certs

    environment:
      RUST_LOG: ${RUST_LOG:-info}
      HTTP_PORT: 80
      HTTPS_PORT: 443
      CERT_DIR: /data/certs
      ACME_EMAIL: ${ACME_EMAIL:-}
      DOMAIN: ${MAIL_DOMAIN:-localhost}

    secrets:
      - proxy_tls_cert
      - proxy_tls_key

    depends_on:
      ai-runtime:
        condition: service_healthy

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # ---------------------------------------------------------------------------
  # Web UI (static files served by nginx)
  # ---------------------------------------------------------------------------
  web-ui:
    image: nginx:alpine
    container_name: gk-web-ui
    restart: unless-stopped

    networks:
      - gk-frontend

    ports:
      - "3000:80"

    volumes:
      - ./web-ui:/usr/share/nginx/html:ro
      - ./nginx.conf:/etc/nginx/nginx.conf:ro

    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 5s
      retries: 3

    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

# =============================================================================
# Networks
# =============================================================================
networks:
  gk-frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/24

  gk-backend:
    driver: bridge
    internal: true  # No external access
    ipam:
      config:
        - subnet: 172.21.0.0/24

  gk-mail:
    driver: bridge
    ipam:
      config:
        - subnet: 172.22.0.0/24

# =============================================================================
# Volumes
# =============================================================================
volumes:
  mail-data:
    driver: local
  mail-maildir:
    driver: local
  mail-queue:
    driver: local
  mail-db:
    driver: local
  ollama-data:
    driver: local
  proxy-certs:
    driver: local

# =============================================================================
# Secrets (use Docker secrets or external secret manager)
# =============================================================================
secrets:
  mail_tls_cert:
    file: ./secrets/mail_tls_cert.pem
  mail_tls_key:
    file: ./secrets/mail_tls_key.pem
  proxy_tls_cert:
    file: ./secrets/proxy_tls_cert.pem
  proxy_tls_key:
    file: ./secrets/proxy_tls_key.pem
  openai_api_key:
    file: ./secrets/openai_api_key.txt
